{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "547a6093",
   "metadata": {},
   "source": [
    "# 2. Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a02999ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82fa7b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this code to make Jupyter print every\n",
    "# printable statement and not just the last one\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# To visualize the data\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generic libraries\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Regression models\n",
    "import sklearn\n",
    "import scipy\n",
    "from scipy.stats import *\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV #split the data into training and test\n",
    "from sklearn.linear_model import LinearRegression #linear regression\n",
    "from sklearn.preprocessing import PolynomialFeatures #for polynomial regression\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# 5-folds crossvalidation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import make_scorer, classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "#classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA\n",
    "from sklearn.neighbors import KNeighborsClassifier "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb4a7cb",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37d14762",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    7807\n",
       "1    1441\n",
       "Name: Revenue, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0    2615\n",
       "1     467\n",
       "Name: Revenue, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set = pd.read_csv(\"training_set_complete.csv\")\n",
    "test_set = pd.read_csv(\"test_set_complete.csv\")\n",
    "training_set = training_set.drop(columns=['Unnamed: 0'])\n",
    "test_set = test_set.drop(columns=['Unnamed: 0'])\n",
    "training_set['Revenue'] = training_set['Revenue'].astype(int)\n",
    "test_set['Revenue'] = test_set['Revenue'].astype(int)\n",
    "training_set['Revenue'].value_counts()\n",
    "test_set['Revenue'].value_counts()\n",
    "categorical_features = ['Month_Aug', 'Month_Dec', 'Month_Feb', 'Month_Jul', 'Month_June',\n",
    "       'Month_Mar', 'Month_May', 'Month_Nov', 'Month_Oct', 'Month_Sep',\n",
    "       'OperatingSystems_1', 'OperatingSystems_2', 'OperatingSystems_3',\n",
    "       'OperatingSystems_4', 'OperatingSystems_5', 'OperatingSystems_6',\n",
    "       'OperatingSystems_7', 'OperatingSystems_8', 'Browser_1', 'Browser_2',\n",
    "       'Browser_3', 'Browser_4', 'Browser_5', 'Browser_6', 'Browser_7',\n",
    "       'Browser_8', 'Browser_9', 'Browser_10', 'Browser_11', 'Browser_12',\n",
    "       'Browser_13', 'Region_1', 'Region_2', 'Region_3', 'Region_4',\n",
    "       'Region_5', 'Region_6', 'Region_7', 'Region_8', 'Region_9',\n",
    "       'TrafficType_1', 'TrafficType_2', 'TrafficType_3', 'TrafficType_4',\n",
    "       'TrafficType_5', 'TrafficType_6', 'TrafficType_7', 'TrafficType_8',\n",
    "       'TrafficType_9', 'TrafficType_10', 'TrafficType_11', 'TrafficType_12',\n",
    "       'TrafficType_13', 'TrafficType_14', 'TrafficType_15', 'TrafficType_16',\n",
    "       'TrafficType_17', 'TrafficType_18', 'TrafficType_19', 'TrafficType_20',\n",
    "       'VisitorType_New_Visitor', 'VisitorType_Other',\n",
    "       'VisitorType_Returning_Visitor', 'Weekend_False', 'Weekend_True']\n",
    "training_set[categorical_features] = training_set[categorical_features].astype('category')\n",
    "test_set[categorical_features] = test_set[categorical_features].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a8acdf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full = training_set.drop(columns=['Revenue'])\n",
    "X_test_full = test_set.drop(columns=['Revenue'])\n",
    "y_train = training_set['Revenue']\n",
    "y_test = test_set['Revenue']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ef0717",
   "metadata": {},
   "source": [
    "### Variance selection\n",
    "We apply variance selection to remove all the features with a very low variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4622c48b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Administrative', 'Administrative_Duration', 'Informational', 'Informational_Duration', 'ProductRelated', 'ProductRelated_Duration', 'BounceRates', 'ExitRates', 'PageValues', 'SpecialDay', 'Month_Aug', 'Month_Dec', 'Month_Feb', 'Month_Jul', 'Month_June', 'Month_Mar', 'Month_May', 'Month_Nov', 'Month_Oct', 'Month_Sep', 'OperatingSystems_1', 'OperatingSystems_2', 'OperatingSystems_3', 'OperatingSystems_4', 'OperatingSystems_6', 'OperatingSystems_8', 'Browser_1', 'Browser_2', 'Browser_3', 'Browser_4', 'Browser_5', 'Browser_6', 'Browser_7', 'Browser_8', 'Browser_10', 'Browser_13', 'Region_1', 'Region_2', 'Region_3', 'Region_4', 'Region_5', 'Region_6', 'Region_7', 'Region_8', 'Region_9', 'TrafficType_1', 'TrafficType_2', 'TrafficType_3', 'TrafficType_4', 'TrafficType_5', 'TrafficType_6', 'TrafficType_7', 'TrafficType_8', 'TrafficType_9', 'TrafficType_10', 'TrafficType_11', 'TrafficType_13', 'TrafficType_15', 'TrafficType_19', 'TrafficType_20', 'VisitorType_New_Visitor', 'VisitorType_Other', 'VisitorType_Returning_Visitor', 'Weekend_False', 'Weekend_True']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "65"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "threshold = 0.001  # Soglia di varianza desiderata\n",
    "variance_selector = VarianceThreshold(threshold=threshold)\n",
    "\n",
    "# Applicazione della selezione della varianza sul dataset\n",
    "\n",
    "X_train = X_train_full.loc[:, variance_selector.fit(X_train_full).get_support()]\n",
    "columns_remaining = X_train.columns.tolist()\n",
    "\n",
    "X_test = X_test_full[columns_remaining]\n",
    "print(X_train.columns.tolist())\n",
    "len(columns_remaining)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e2ae20",
   "metadata": {},
   "source": [
    "### Functions and algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dfbd150",
   "metadata": {},
   "source": [
    "#### Feature selection: Forward stepwise selection\n",
    "We chose this algorithm because it's more scalable on a big dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f488230e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "def get_evaluator(scorer):\n",
    "    def evaluator(model, X, y, trained=False):\n",
    "        if not trained:\n",
    "            model = model.fit(X, y)\n",
    "        score = scorer(model, X, y)\n",
    "        return model, score\n",
    "    return evaluator   \n",
    "\n",
    "def get_cv_evaluator(scorer, cv=3):\n",
    "    def evaluator(model, X, y, trained=False):            \n",
    "        scores = cross_val_score(model, X, y, scoring=scorer, cv=cv)\n",
    "        if not trained:\n",
    "            model = model.fit(X, y)\n",
    "        return model, np.mean(scores)\n",
    "    \n",
    "    return evaluator\n",
    "\n",
    "def get_val_evaluator(scorer, val_size=0.1):\n",
    "    def evaluator(model, X, y, trained=False):\n",
    "        X_train_small, X_val, y_train_small, y_val = train_test_split(X, y, \n",
    "                                                                      test_size=val_size,\n",
    "                                                                      random_state=0)\n",
    "        \n",
    "        if not trained:\n",
    "            model = model.fit(X_train_small, y_train_small)\n",
    "        score = scorer(model, X_val, y_val) \n",
    "        \n",
    "        return model, score\n",
    "    \n",
    "    return evaluator\n",
    "\n",
    "\n",
    "possible_models = {\n",
    "    \"LogisticRegression\":LogisticRegression(solver=\"newton-cg\", penalty='none',max_iter=1000),\n",
    "    \"LDA\":LDA(),\n",
    "    \"QDA\":QDA(),\n",
    "    #\"KNN\":KNeighborsClassifier(n_neighbors=6),\n",
    "    \"LinearRegression\":LinearRegression(fit_intercept=True),\n",
    "}\n",
    "\n",
    "def forward_selection(Xtrain_pd, ytrain, Xtest_pd, ytest,model_chosen,\n",
    "                      candidates_evaluator, candidates_argbest, # Metric to be used at 2.b\n",
    "                      subsets_evaluator, subsets_argbest,       # Metric to be used at 3\n",
    "                      test_evaluator=None, test_argbest=None,\n",
    "                      candidates_scorer_name=None,  # Name of 2. figure\n",
    "                      subsets_scorer_name=None,     # Name of 3. figure\n",
    "                      verbose=True, weight_step3=0):   \n",
    "    test_evaluator = subsets_evaluator if not test_evaluator else test_evaluator\n",
    "    test_argbest = subsets_argbest if not test_argbest else test_argbest\n",
    "    \n",
    "    # Global variable init\n",
    "    # ====================\n",
    "    num_features = Xtrain_pd.shape[-1]\n",
    "    best_candidate_metric = []\n",
    "    # subsets_* are lists containing one value for each Mk model (the best of the Mk candidates)\n",
    "    subsets_test = []\n",
    "    subsets_metric = []        # The best metric of each subset of dimension 'dim'\n",
    "    subsets_best_features = [] # The best features combination in each subset of dimension 'dim'\n",
    "    # A figure to keep track of candidates scores in each Mk subset\n",
    "    num_evaluations = 0        # A conter to keep track of the total number of trials\n",
    "    \n",
    "    selected_features = []\n",
    "    all_features = Xtrain_pd.columns\n",
    "    \n",
    "    \n",
    "    # 1. Train M0\n",
    "    # ===========\n",
    "    model = DummyRegressor()\n",
    "    # Compute (2.b) metrics\n",
    "    model, score = candidates_evaluator(model, Xtrain_pd[[]], ytrain)\n",
    "    best_candidate_metric.append(score)\n",
    "    subsets_best_features.append([])\n",
    "    # Compute metric for step 3.\n",
    "    _, score = subsets_evaluator(model, Xtrain_pd[[]], ytrain, trained=True)\n",
    "    subsets_metric.append(score)\n",
    "    _, score = test_evaluator(model, Xtrain_pd[[]], ytrain, trained=True)\n",
    "    subsets_test.append(score)\n",
    "    \n",
    "    \n",
    "    for dim in range(num_features):\n",
    "        candidate_metrics = [] # metrics for all the models with dim features\n",
    "        candidate_models = []  # models with dim features\n",
    "        \n",
    "        remaining_features = all_features.difference(selected_features)\n",
    "        \n",
    "        # fit all the models with k features\n",
    "        for new_column in remaining_features:\n",
    "            Xtrain_sub = Xtrain_pd[selected_features+[new_column]].to_numpy()\n",
    "            model = possible_models[model_chosen]\n",
    "            #print(new_column)\n",
    "            model, score = candidates_evaluator(model, Xtrain_sub, ytrain)\n",
    "            candidate_models.append(model)\n",
    "            candidate_metrics.append(score)\n",
    "            num_evaluations += 1\n",
    "            \n",
    "        \n",
    "        idx_best_candidate = candidates_argbest(candidate_metrics) # select the best Mk model\n",
    "        selected_features.append(remaining_features[idx_best_candidate]) # Update selected feature\n",
    "        best_candidate_metric.append(candidate_metrics[idx_best_candidate]) # Save best candidate features\n",
    "        best_features = selected_features.copy()\n",
    "        subsets_best_features.append(best_features)\n",
    "        \n",
    "        \n",
    "        # Compute metric for the final step -> comparison of all the best models\n",
    "        best_subset_model = candidate_models[idx_best_candidate] # save the best model\n",
    "        best_subset_Xtrain = Xtrain_pd[best_features].to_numpy()\n",
    "        best_subset_Xtest = Xtest_pd[best_features].to_numpy()\n",
    "        _, score = test_evaluator(best_subset_model, best_subset_Xtest, ytest, trained=True)\n",
    "        subsets_test.append(score) # computing the metrics for the test set\n",
    "        _, score = subsets_evaluator(best_subset_model, best_subset_Xtrain, ytrain, trained=True)\n",
    "        subsets_metric.append(score) #computing the metrics for the training set\n",
    "        num_evaluations += weight_step3 \n",
    "        \n",
    "        if verbose:\n",
    "            print(\"............\")\n",
    "            print(\"Best model (M{}) with {} features: {}\".format(dim+1, dim+1, best_features))\n",
    "            print(\"M{} subset score (3.): {}\".format(dim+1, score))\n",
    "        \n",
    "    # choose the best candidates\n",
    "    best_subset_idx = subsets_argbest(subsets_metric)\n",
    "    best_features = subsets_best_features[best_subset_idx]\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"\\n Best configuration has {} features\".format(best_subset_idx))\n",
    "        print(\"Features: {}\".format(subsets_best_features[best_subset_idx]))\n",
    "        print(\"Total number of trained models:\", num_evaluations)\n",
    "    \n",
    "    # Complete the subsets_fig figure by plotting\n",
    "    # a line connecting all best candidate score\n",
    "    best_candidate_score_idx = candidates_argbest(best_candidate_metric)\n",
    "    \n",
    "    best_test_score_idx = test_argbest(subsets_test)\n",
    "    return best_features\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06c7e91",
   "metadata": {},
   "source": [
    "#### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6fd571b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_pred, y_true):\n",
    "    return (y_pred == y_true).mean()\n",
    "\n",
    "def calculate_sensitivity_specificity(confusion_matrix):\n",
    "    # Extract values from the confusion matrix\n",
    "    TN, FP, FN, TP = confusion_matrix.ravel()\n",
    "\n",
    "    # Calculate Sensitivity (Recall)\n",
    "    sensitivity = TP / (TP + FN)\n",
    "\n",
    "    # Calculate Specificity\n",
    "    specificity = TN / (TN + FP)\n",
    "\n",
    "    return sensitivity, specificity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982a7418",
   "metadata": {},
   "source": [
    "#### Evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "160e03e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def classification_metrics_training(model, model_name, X_train, y_train, cv):\n",
    "    #sensitivity\n",
    "    sensitivity_train = np.mean(np.absolute(cross_val_score(model, X_train, y_train, cv=cv, scoring='recall', n_jobs=-1)))\n",
    "    \n",
    "    #specificity\n",
    "    specificity_train = np.mean(np.absolute(cross_val_score(model, X_train, y_train, cv=cv, scoring='precision', n_jobs=-1)))\n",
    "    \n",
    "    #accuracy\n",
    "    accuracy_train = np.mean(np.absolute(cross_val_score(model, X_train, y_train, cv=cv, scoring='accuracy', n_jobs=-1)))\n",
    "                         \n",
    "    # building a dataframe\n",
    "    data = {\n",
    "        'Model': [model_name],\n",
    "        'Accuracy': [accuracy_train],\n",
    "        'Sensitivity': [sensitivity_train],\n",
    "        'Specificity': [specificity_train],\n",
    "    }\n",
    "    return pd.DataFrame(data)                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e866b1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_metrics_test(model, model_name,X_train,y_train,X_test,y_test,threshold):\n",
    "    # building the confusion matrix for test performances\n",
    "    model = model.fit(X_train,y_train)\n",
    "    #ypred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]  # Probability of positive class (class 1)\n",
    "\n",
    "    # Convert probabilities to binary predictions\n",
    "    ypred = (y_pred_proba > threshold).astype(int)\n",
    "    \n",
    "    cm = confusion_matrix(y_test.to_numpy(), np.array(ypred))\n",
    "    sensitivity_test, specificity_test = calculate_sensitivity_specificity(cm)\n",
    "    \n",
    "    accuracy_test = accuracy(ypred, y_test)\n",
    "    \n",
    "    # building a dataframe\n",
    "    data = {\n",
    "        'Model': [model_name],\n",
    "        'Accuracy': [accuracy_test],\n",
    "        'Sensitivity': [sensitivity_test],\n",
    "        'Specificity': [specificity_test],\n",
    "    }\n",
    "    return pd.DataFrame(data), cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd019a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We compute the empirical threshold\n",
    "empirical_threshold = y_train.mean()\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "def classification_metrics_empirical_threshold(model, model_name, X_train, y_train,threshold=0.5):\n",
    "    \n",
    "    model = model.fit(X_train, y_train)\n",
    "    \n",
    "    # Get predicted probabilities\n",
    "    y_pred_proba = model.predict_proba(X_train)[:, 1]  # Probability of positive class (class 1)\n",
    "\n",
    "    # Convert probabilities to binary predictions\n",
    "    y_pred = (y_pred_proba > threshold).astype(int)\n",
    "\n",
    "    # Evaluate the performance using various metrics\n",
    "    accuracy = accuracy_score(y_train, y_pred)\n",
    "    specificity = precision_score(y_train, y_pred)\n",
    "    sensitivity = recall_score(y_train, y_pred)\n",
    "    f1 = f1_score(y_train, y_pred)\n",
    "    \n",
    "    data = {\n",
    "        'Model': [model_name],\n",
    "        'Accuracy': [accuracy],\n",
    "        'Sensitivity': [sensitivity],\n",
    "        'Specificity': [specificity],\n",
    "    }\n",
    "    return pd.DataFrame(data) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12901cd6",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792f64c9",
   "metadata": {},
   "source": [
    "### Scaling data\n",
    "We scale the numerical features to avoid convergence problem with logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f0fd591a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FACCIAMO QUESTO STEP PER EVITARE PROBLEMI DI CONVERGENZA NEL MODELLO\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Assuming you have your feature data X\n",
    "numeric_features = ['Administrative', 'Administrative_Duration', 'Informational',\n",
    "       'Informational_Duration', 'ProductRelated', 'ProductRelated_Duration',\n",
    "       'BounceRates', 'ExitRates', 'PageValues', 'SpecialDay']\n",
    "categorical_features = ['Month_Aug', 'Month_Dec', 'Month_Feb', 'Month_Jul', 'Month_June', 'Month_Mar', 'Month_May', \n",
    "                        'Month_Nov', 'Month_Oct', 'Month_Sep', 'OperatingSystems_1', 'OperatingSystems_2', 'OperatingSystems_3', 'OperatingSystems_4', 'OperatingSystems_6', 'OperatingSystems_8', 'Browser_1', 'Browser_2', 'Browser_3', 'Browser_4', 'Browser_5', 'Browser_6', 'Browser_7', 'Browser_8', 'Browser_10', 'Browser_13', 'Region_1', 'Region_2', 'Region_3', 'Region_4', 'Region_5',\n",
    "                        'Region_6', 'Region_7', 'Region_8', 'Region_9', 'TrafficType_1', 'TrafficType_2', \n",
    "                        'TrafficType_3', 'TrafficType_4', 'TrafficType_5', 'TrafficType_6', 'TrafficType_7', \n",
    "                        'TrafficType_8', 'TrafficType_9', 'TrafficType_10', 'TrafficType_11', 'TrafficType_13', \n",
    "                        'TrafficType_15', 'TrafficType_19', 'TrafficType_20', 'VisitorType_New_Visitor', 'VisitorType_Other', 'VisitorType_Returning_Visitor', 'Weekend_False', 'Weekend_True']\n",
    "scaler = StandardScaler()\n",
    "train_scaled = pd.DataFrame(scaler.fit_transform(X_train[numeric_features]))\n",
    "test_scaled = pd.DataFrame(scaler.fit_transform(X_test[numeric_features]))\n",
    "train_scaled.columns = X_train[numeric_features].columns\n",
    "test_scaled.columns = X_test[numeric_features].columns\n",
    "X_train_scaled = pd.concat([train_scaled,X_train[categorical_features]],axis=1)\n",
    "X_test_scaled = pd.concat([test_scaled,X_test[categorical_features]],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687db0bf",
   "metadata": {},
   "source": [
    "### Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "535ef449",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PageValues',\n",
       " 'VisitorType_New_Visitor',\n",
       " 'TrafficType_3',\n",
       " 'TrafficType_10',\n",
       " 'Browser_7',\n",
       " 'Region_8',\n",
       " 'TrafficType_11',\n",
       " 'Browser_3',\n",
       " 'Browser_8',\n",
       " 'Month_Feb',\n",
       " 'Browser_1',\n",
       " 'OperatingSystems_8',\n",
       " 'Region_5',\n",
       " 'Month_Aug',\n",
       " 'TrafficType_7',\n",
       " 'TrafficType_9',\n",
       " 'Region_2',\n",
       " 'Browser_13',\n",
       " 'OperatingSystems_6',\n",
       " 'Browser_4',\n",
       " 'VisitorType_Other',\n",
       " 'Browser_5',\n",
       " 'Region_6']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = 5\n",
    "features_logistic = forward_selection(X_train_scaled, y_train, X_test_scaled, y_test,\"LogisticRegression\",\n",
    "                  get_evaluator(make_scorer(accuracy)), np.argmax, # 2.\n",
    "                  get_cv_evaluator(make_scorer(accuracy), cv), np.argmax, # 3.\n",
    "                  get_evaluator(make_scorer(accuracy)), np.argmax, # test\n",
    "                  candidates_scorer_name=\"Accuracy\",\n",
    "                  subsets_scorer_name=\"Accuracy (CV)\",\n",
    "                  verbose=False, weight_step3=cv)\n",
    "features_logistic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6efe8489",
   "metadata": {},
   "source": [
    "### Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dcc10a78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.884515</td>\n",
       "      <td>0.365686</td>\n",
       "      <td>0.773116</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Model  Accuracy  Sensitivity  Specificity\n",
       "0  LogisticRegression  0.884515     0.365686     0.773116"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_logistic = LogisticRegression(solver=\"newton-cg\",penalty=\"none\",max_iter=1000)\n",
    "train_scores_logistic = classification_metrics_training(model_logistic, \"LogisticRegression\", X_train_scaled[features_logistic], y_train,5)\n",
    "train_scores_logistic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec82040",
   "metadata": {},
   "source": [
    "The sensitivity is very low, we try to improve it using the empirical threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bf18bb67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.88138</td>\n",
       "      <td>0.646079</td>\n",
       "      <td>0.613307</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Model  Accuracy  Sensitivity  Specificity\n",
       "0  LogisticRegression   0.88138     0.646079     0.613307"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_scores_logistic_empirical = classification_metrics_empirical_threshold(model_logistic, 'LogisticRegression', X_train_scaled[features_logistic], y_train,empirical_threshold)\n",
    "train_scores_logistic_empirical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "efcb6a1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.893251</td>\n",
       "      <td>0.67666</td>\n",
       "      <td>0.931931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Model  Accuracy  Sensitivity  Specificity\n",
       "0  LogisticRegression  0.893251      0.67666     0.931931"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_scores_logistic, cm_logistic = classification_metrics_test(model_logistic,\"LogisticRegression\", X_train_scaled[features_logistic], y_train,X_test_scaled[features_logistic], y_test,empirical_threshold)\n",
    "test_scores_logistic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17bd991c",
   "metadata": {},
   "source": [
    "# LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc563bb6",
   "metadata": {},
   "source": [
    "### Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "29d04943",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PageValues',\n",
       " 'ExitRates',\n",
       " 'BounceRates',\n",
       " 'Month_Oct',\n",
       " 'VisitorType_Other',\n",
       " 'TrafficType_5',\n",
       " 'OperatingSystems_1',\n",
       " 'Browser_3',\n",
       " 'Browser_7',\n",
       " 'Browser_8',\n",
       " 'Month_Aug',\n",
       " 'Month_Sep',\n",
       " 'OperatingSystems_4',\n",
       " 'Month_Feb',\n",
       " 'Region_3',\n",
       " 'Browser_4',\n",
       " 'Region_7',\n",
       " 'TrafficType_11',\n",
       " 'TrafficType_10',\n",
       " 'OperatingSystems_6',\n",
       " 'OperatingSystems_8',\n",
       " 'Region_5',\n",
       " 'Region_6',\n",
       " 'TrafficType_15',\n",
       " 'TrafficType_19',\n",
       " 'TrafficType_4']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = 5\n",
    "features_LDA = forward_selection(X_train_scaled, y_train, X_test_scaled, y_test,\"LDA\",\n",
    "                  get_evaluator(make_scorer(accuracy)), np.argmax, # 2.\n",
    "                  get_cv_evaluator(make_scorer(accuracy), cv), np.argmax, # 3.\n",
    "                  get_evaluator(make_scorer(accuracy)), np.argmax, # test\n",
    "                  candidates_scorer_name=\"Accuracy\",\n",
    "                  subsets_scorer_name=\"Accuracy (CV)\",\n",
    "                  verbose=False, weight_step3=cv)\n",
    "features_LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a043ba09",
   "metadata": {},
   "source": [
    "### Evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dc267b38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LDA</td>\n",
       "      <td>0.880839</td>\n",
       "      <td>0.325442</td>\n",
       "      <td>0.782345</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model  Accuracy  Sensitivity  Specificity\n",
       "0   LDA  0.880839     0.325442     0.782345"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_LDA =LDA(store_covariance=True)\n",
    "train_scores_LDA = classification_metrics_training(model_LDA, \"LDA\", X_train[features_LDA], y_train, 5)\n",
    "train_scores_LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b16029",
   "metadata": {},
   "source": [
    "We try to improve the sensitivity by setting the empirical threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b1e3cb3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LDA</td>\n",
       "      <td>0.889273</td>\n",
       "      <td>0.56211</td>\n",
       "      <td>0.673317</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model  Accuracy  Sensitivity  Specificity\n",
       "0   LDA  0.889273      0.56211     0.673317"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_scores_LDA_empirical = classification_metrics_empirical_threshold(model_LDA, 'LDA', X_train_scaled[features_LDA], y_train,empirical_threshold)\n",
    "train_scores_LDA_empirical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8d784655",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LDA</td>\n",
       "      <td>0.899416</td>\n",
       "      <td>0.61242</td>\n",
       "      <td>0.950669</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model  Accuracy  Sensitivity  Specificity\n",
       "0   LDA  0.899416      0.61242     0.950669"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_scores_LDA, cm_LDA = classification_metrics_test(model_LDA, \"LDA\",X_train[features_LDA], y_train,X_test[features_LDA], y_test,empirical_threshold)\n",
    "test_scores_LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0d07a9",
   "metadata": {},
   "source": [
    "## QDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6265074c",
   "metadata": {},
   "source": [
    "### Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0ee0e365",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PageValues', 'BounceRates', 'VisitorType_New_Visitor', 'Browser_7']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "cv = 5\n",
    "features_QDA = forward_selection(X_train_scaled, y_train, X_test_scaled, y_test,\"QDA\",\n",
    "                  get_evaluator(make_scorer(accuracy)), np.argmax, # 2.\n",
    "                  get_cv_evaluator(make_scorer(accuracy), cv), np.argmax, # 3.\n",
    "                  get_evaluator(make_scorer(accuracy)), np.argmax, # test\n",
    "                  candidates_scorer_name=\"Accuracy\",\n",
    "                  subsets_scorer_name=\"Accuracy (CV)\",\n",
    "                  verbose=False, weight_step3=cv)\n",
    "features_QDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7033b22a",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4cb46676",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>QDA</td>\n",
       "      <td>0.889706</td>\n",
       "      <td>0.46423</td>\n",
       "      <td>0.729627</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model  Accuracy  Sensitivity  Specificity\n",
       "0   QDA  0.889706      0.46423     0.729627"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_QDA = QDA(store_covariance=True)\n",
    "train_scores_QDA = classification_metrics_training(model_QDA, \"QDA\", X_train[features_QDA], y_train, 5)\n",
    "train_scores_QDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723e77d7",
   "metadata": {},
   "source": [
    "The sensitivity is very high with respect to the specificity, so we try to set the empirical threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b9f41197",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>QDA</td>\n",
       "      <td>0.800822</td>\n",
       "      <td>0.686329</td>\n",
       "      <td>0.415721</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model  Accuracy  Sensitivity  Specificity\n",
       "0   QDA  0.800822     0.686329     0.415721"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_scores_QDA_empirical = classification_metrics_empirical_threshold(model_QDA, 'QDA', X_train_scaled[features_QDA], y_train, empirical_threshold)\n",
    "train_scores_QDA_empirical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "26be5e89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>QDA</td>\n",
       "      <td>0.815704</td>\n",
       "      <td>0.728051</td>\n",
       "      <td>0.831358</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model  Accuracy  Sensitivity  Specificity\n",
       "0   QDA  0.815704     0.728051     0.831358"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_scores_QDA, cm_QDA = classification_metrics_test(model_QDA,\"QDA\",X_train[features_QDA], y_train,X_test[features_QDA], y_test,empirical_threshold)\n",
    "test_scores_QDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d91233d5",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a20dd3a",
   "metadata": {},
   "source": [
    "### With all features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f3215791",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f92da8ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=KNeighborsClassifier(),\n",
       "             param_grid={'n_neighbors': range(1, 15)},\n",
       "             scoring=make_scorer(accuracy))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_KNN_all = KNeighborsClassifier()\n",
    "params = {'n_neighbors': range(1, 15)}\n",
    "cv = GridSearchCV(model_KNN_all, params, refit=True, cv=10, \n",
    "                  scoring=make_scorer(accuracy))\n",
    "cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "04a2d1a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.862673</td>\n",
       "      <td>0.211649</td>\n",
       "      <td>0.694549</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model  Accuracy  Sensitivity  Specificity\n",
       "0   KNN  0.862673     0.211649     0.694549"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "model_KNN_all = KNeighborsClassifier(n_neighbors=cv.best_params_['n_neighbors'])\n",
    "train_scores_KNN_all = classification_metrics_training(model_KNN_all, \"KNN\", X_train, y_train, 5)\n",
    "train_scores_KNN_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5a86f80c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.728482</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.364626</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model  Accuracy  Sensitivity  Specificity\n",
       "0   KNN  0.728482          1.0     0.364626"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_scores_KNN_all_empirical = classification_metrics_empirical_threshold(model_KNN_all, 'KNN', X_train, y_train,empirical_threshold)\n",
    "train_scores_KNN_all_empirical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "481e7fa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.665152</td>\n",
       "      <td>0.815846</td>\n",
       "      <td>0.638241</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model  Accuracy  Sensitivity  Specificity\n",
       "0   KNN  0.665152     0.815846     0.638241"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_scores_KNN_all, cm_KNN_all = classification_metrics_test(model_KNN_all, \"KNN\", X_train, y_train, X_test, y_test,empirical_threshold)\n",
    "test_scores_KNN_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc0b4fc",
   "metadata": {},
   "source": [
    "### With only numeric features\n",
    "KNN has two main issues: \n",
    "1. It is not scalable with a large amount of features\n",
    "2. It relies on a distance metric to compute the distance between points. This distance may not be significant in case of categorical variables (even if we use one-hot encoding)\n",
    "3. From the previous analysis we can also notice that even with the empirical threshold the performances don't improve significantly\n",
    "\n",
    "So for these reasons we also fit a model with just the numeric features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "00843bca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=KNeighborsClassifier(),\n",
       "             param_grid={'n_neighbors': range(1, 50)},\n",
       "             scoring=make_scorer(accuracy))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_KNN_numeric = KNeighborsClassifier()\n",
    "params = {'n_neighbors': range(1, 50)}\n",
    "cv = GridSearchCV(model_KNN_numeric, params, refit=True, cv=10, \n",
    "                  scoring=make_scorer(accuracy))\n",
    "cv.fit(X_train[numeric_features], y_train)\n",
    "model_KNN_numeric = KNeighborsClassifier(n_neighbors=cv.best_params_['n_neighbors'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b9984ba5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.862565</td>\n",
       "      <td>0.210955</td>\n",
       "      <td>0.693827</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model  Accuracy  Sensitivity  Specificity\n",
       "0   KNN  0.862565     0.210955     0.693827"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_scores_KNN_numeric = classification_metrics_training(model_KNN_numeric, \"KNN\", X_train[numeric_features], y_train, 5)\n",
    "train_scores_KNN_numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0611f3e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.727941</td>\n",
       "      <td>0.998612</td>\n",
       "      <td>0.364027</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model  Accuracy  Sensitivity  Specificity\n",
       "0   KNN  0.727941     0.998612     0.364027"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_scores_KNN_numeric_empirical = classification_metrics_empirical_threshold(model_KNN_numeric, 'KNN', X_train[numeric_features], y_train, empirical_threshold)\n",
    "train_scores_KNN_numeric_empirical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "70850e13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.664828</td>\n",
       "      <td>0.815846</td>\n",
       "      <td>0.637859</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model  Accuracy  Sensitivity  Specificity\n",
       "0   KNN  0.664828     0.815846     0.637859"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_score_KNN_numeric, cm_KNN_numeric = classification_metrics_test(model_KNN_numeric, \"KNN\",X_train[numeric_features], y_train, X_test[numeric_features], y_test,empirical_threshold)\n",
    "test_score_KNN_numeric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7590e1",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e61e1bc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tempo totale di esecuzione: 8.67 minuti\n"
     ]
    }
   ],
   "source": [
    "end_time = time.time()\n",
    "total_time = (end_time - start_time)/60\n",
    "\n",
    "print(f\"Tempo totale di esecuzione: {total_time:.2f} minuti\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46e505b0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train_scaled' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14488\\917839733.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# Applica PCA\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mpca\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPCA\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mX_train_pca\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpca\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_scaled\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# Calcola la percentuale di varianza spiegata cumulativa\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train_scaled' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Applica PCA\n",
    "pca = PCA()\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "\n",
    "# Calcola la percentuale di varianza spiegata cumulativa\n",
    "explained_variance_ratio_cumsum = np.cumsum(pca.explained_variance_ratio_)\n",
    "\n",
    "# Trova il numero di componenti che catturano il 95% della varianza\n",
    "n_components = np.argmax(explained_variance_ratio_cumsum >= 0.95) + 1 #27\n",
    "\n",
    "# Riduci la dimensionalità del dataset utilizzando il numero selezionato di componenti principali\n",
    "pca = PCA(n_components=n_components)\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "# Addestra una SVM sulle componenti principali ottenute\n",
    "svm_model = SVC(kernel='linear', C=1.0, random_state=42) # E' PIU' ACCURATO LINEAR\n",
    "#svm_model = SVC(kernel='poly', degree=3, coef0=-5, C=5)\n",
    "svm_model.fit(X_train_pca, y_train)\n",
    "\n",
    "# Fai le previsioni sul set di test\n",
    "y_pred = svm_model.predict(X_test_pca)\n",
    "\n",
    "# Calcola l'accuratezza del modello\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuratezza del modello SVM con PCA:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1871cb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "    'gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "# Step 4: Create the SVM classifier\n",
    "svm_model = SVC()\n",
    "\n",
    "# Step 5: Perform grid search using cross-validation\n",
    "grid_search = GridSearchCV(svm_model, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Step 6: Get the best kernel and its parameters\n",
    "best_kernel = grid_search.best_params_['kernel']\n",
    "best_C = grid_search.best_params_['C']\n",
    "best_gamma = grid_search.best_params_['gamma']\n",
    "best_kernel\n",
    "best_C\n",
    "best_gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36026f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "kernels = ['linear', 'rbf', 'poly', 'sigmoid']\n",
    "score = []\n",
    "for kern in kernels:\n",
    "    cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
    "    model_SVM = SVC(kernel=kern)\n",
    "    scores = cross_val_score(model_SVM, X_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "    score.append(np.mean(scores))\n",
    "max_index = score.index(max(score))\n",
    "best_kernel = kernels[max_index]\n",
    "acc_best_model = max(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b53192",
   "metadata": {},
   "outputs": [],
   "source": [
    "X0_range = (X_train_pca[:,0].min(), X_train_pca[:,0].max())\n",
    "X1_range = (X_train_pca[:,1].min(), X_train_pca[:,1].max())\n",
    "\n",
    "sns.scatterplot(x=X_train_pca[:,0], y=X_train_pca[:,1], hue=y_train, marker='o')\n",
    "sns.scatterplot(x=X_test_pca[:,0], y=X_test_pca[:,1], hue=y_test, marker='^')\n",
    "\n",
    "\n",
    "#plot_svm_line(svm_model, X0_range, X1_range, label=\"SVM\")\n",
    "#_ = plt.axis([X0_range[0]-0.5, X0_range[1]+0.5, X1_range[0]-0.5, X1_range[1]+0.5])\n",
    "\n",
    "train_acc = accuracy_score(y_train, svm_model.predict(X_train_pca))\n",
    "test_acc = accuracy_score(y_test, svm_model.predict(X_test_pca))\n",
    "print(\"Train score: {}\".format(train_acc))\n",
    "print(\"Test score: {}\".format(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fff5c13",
   "metadata": {},
   "source": [
    "[Vai alla Sezione 1](#Classification)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
