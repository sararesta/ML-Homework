1. sistemare visual inspection VALE
	- !!usare il training set senza missing values
	- !!revenue vs continue -> boxplot
	- !!revenue vs categoriche -> chi-squared 
	- !!tabella che dice se i pvalue sono significativi o no
	- !!considerazioni su exit rates
	- !!exitrates vs continue
	- !!exit rates vs categoriche -> boxplot
2. fare svm -> capire come fare feature selection SARA
3. PCA -> capire se si può usare sulla classification SARA -> FUTURO
4. residual plot nella regression VALE
5. !!variance threshold nella regression VALE
6. rifare regression con lasso e confrontare i risultati con forward stepwise VALE
7. KNN sulle continue -> futuro
8. sistemare sensitivity -> SARA
	- sistema il discorso empirical threshold
	- sistema la threshold con cui si fanno le predizioni per il test! 
		a. y_pred_prob_test = model.predict_proba(X_test)[:, 1]
		b. y_pred = (y_pred_prob_test >= new_threshold).astype(int)
9. Regression: sistemare l'algoritmo di feature selection: non deve contenere la parte relativa a test set -> sistemalo e rirunna tutto, anche se poi probabilmente userai quello generico con il dizionario. A proposito, forse il dizionario è un po' rudimentale: cerca di trovare una maniera carina per sistemarlo (se riesci a fare i puntatori a funzione come il prof top!!) SARA


1. CONTROLLARE SE I PVALUE CHE ESCONO SONO COERENTI CON QUELLO CHE POI ESCE IN CLASSIFICATION
2. FARE QUALCHE CONSIDERAZIONE SUI BOXPLOT DI EXITRATES ALLA LUCE DI QUELLO CHE CI USCIRA'
3. Dobbiamo spiegare perchè nel confronto con ExitRates non mettiamo Revenue?
4. Makescorer ...
5. Va cambiato qualcosa nella linear? Bisogna cross-validare?
6. Scaler scala anche le categoriche?


!!SISTEMARE PVALUES VISUAL --> Vale
!!REGRESSION --> Vale
!!1. Polynomial già a posto --> esce grado 1
!!1.2 Linear da sola
!!2. Linear con Ridge
!!3. Linear con Lasso
4. Linear con forward
4.2 KNN
5. Valutazione della cosa migliore

- Ogni volta quando si calcolano i parametri va crossvalidato. --> funzione di scikit. --> cross_val_score.