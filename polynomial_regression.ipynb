{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f2f06886",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this code to make Jupyter print every\n",
    "# printable statement and not just the last one\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# To visualize the data\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generic libraries\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Regression models\n",
    "import sklearn\n",
    "import scipy\n",
    "from scipy.stats import t\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split #split the data into training and test\n",
    "from sklearn.linear_model import LinearRegression #linear regression\n",
    "from sklearn.preprocessing import PolynomialFeatures #for polynomial regression\n",
    "from sklearn.metrics import r2_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf8b05a",
   "metadata": {},
   "source": [
    "# Polynomial regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64182dfb",
   "metadata": {},
   "source": [
    "Import the datasets (for this step we need only the training set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d21ec1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "online_shoppers = pd.read_csv(\"data/online_shoppers_intention.csv\")\n",
    "training_set = pd.read_csv(\"data/training_set_online_shoppers_intention.csv\")\n",
    "test_set = pd.read_csv(\"data/test_set_online_shoppers_intention.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e0fe44",
   "metadata": {},
   "source": [
    "We set all the categorical types as category $\\rightarrow$ non so se sia davvero utile o no, magari lo teniamo solo per la heatmap, CONTROLLARE!!!\n",
    "Non so se sia utile per il fatto che poi tutte le categoriche diventano dummy variables, quindi in realtà "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0eb9b258",
   "metadata": {},
   "outputs": [],
   "source": [
    "online_shoppers['Month']=online_shoppers['Month'].astype('category')\n",
    "online_shoppers['OperatingSystems']=online_shoppers['OperatingSystems'].astype('category')\n",
    "online_shoppers['Browser']=online_shoppers['Browser'].astype('category')\n",
    "online_shoppers['Region']=online_shoppers['Region'].astype('category')\n",
    "online_shoppers['TrafficType']=online_shoppers['TrafficType'].astype('category')\n",
    "online_shoppers['VisitorType']=online_shoppers['VisitorType'].astype('category')\n",
    "online_shoppers['Weekend']=online_shoppers['Weekend'].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a50548",
   "metadata": {},
   "source": [
    "Here we group the categories with the lowest number of elements into 'others'. Since these categories doesn't have a significant number of elements we don't expect them to be significant. Giving too many importance to them may lead to overfitting problems (di questa cosa non sono sicura ed è anche scritta in un inglese che fa pena)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "70b244db",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# VisitorType -> others removed\n",
    "training_set = training_set[training_set['VisitorType']!='Other']\n",
    "\n",
    "#VisitorType -> 1 = returning, 0 = new\n",
    "training_set['VisitorType'] = np.where(training_set['VisitorType']=='Returning_Visitor',1,0)\n",
    "\n",
    "# Weekend\n",
    "training_set['Weekend'] = np.where(training_set['Weekend']=='False',1,0)\n",
    "\n",
    "# Split categorical variables\n",
    "months = pd.get_dummies(training_set.Month, prefix='Month')\n",
    "regions = pd.get_dummies(training_set.Region, prefix='Region')\n",
    "\n",
    "def cut_levels(x, threshold, new_value):\n",
    "    x = x.copy()\n",
    "    value_counts = x.value_counts()\n",
    "    labels = value_counts.index[value_counts < threshold]\n",
    "    x[np.in1d(x, labels)] = new_value\n",
    "    return x\n",
    "\n",
    "training_set['Browser'] = cut_levels(training_set['Browser'],100,'Others')\n",
    "training_set['TrafficType'] = cut_levels(training_set['TrafficType'],100,'Others')\n",
    "training_set['OperatingSystems'] = cut_levels(training_set['OperatingSystems'],100,'Others')\n",
    "\n",
    "browser = pd.get_dummies(training_set.Browser, prefix='Browser')\n",
    "traffic_type = pd.get_dummies(training_set.TrafficType, prefix='TrafficType')\n",
    "operating_systems = pd.get_dummies(training_set.OperatingSystems, prefix='OperatingSystems')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ee3407",
   "metadata": {},
   "source": [
    "Here we replace the categorical features with the dummies variables obtaining binary features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5f721f57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9182, 56)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set = training_set.drop(['Unnamed: 0','Month','Region','Browser','TrafficType','OperatingSystems','VisitorType'], axis=1).join([months,regions,browser,traffic_type,operating_systems])\n",
    "training_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3219dd24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the training set to separate the rows with missing values\n",
    "mask = training_set['ExitRates'].isna()\n",
    "training_set_missing = training_set[mask]\n",
    "#training_set_missing.head()\n",
    "training_set_no_missing = training_set[mask==False]\n",
    "#training_set_no_missing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "943a84d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all_features = list(np.delete(training_set.columns.values, [np.where(training_set.columns.values=='ExitRates'),np.where(training_set.columns.values=='Revenue')], axis=None))\n",
    "X = training_set_no_missing[X_all_features].to_numpy()\n",
    "y = training_set_no_missing['ExitRates'].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e496046",
   "metadata": {},
   "source": [
    "Now we split the training data to obtain a train and a test set to train the regression model and to compute the performance scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2fc6a037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape  (4492, 54)\n",
      "X_test.shape  (1926, 54)\n"
     ]
    }
   ],
   "source": [
    "#splitting data\n",
    "test_size = 0.3\n",
    "test_seed = 40\n",
    "# Split X and y into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=test_seed)\n",
    "print(\"X_train.shape \", X_train.shape)\n",
    "print(\"X_test.shape \", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8a0536cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_small, X_test_small, y_train_small, y_test_small = train_test_split(X, y,\n",
    "                                                                test_size=test_size, \n",
    "                                                                random_state=test_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c2f100",
   "metadata": {},
   "source": [
    "Now we fit different polynomial regression models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e9357969",
   "metadata": {},
   "outputs": [],
   "source": [
    "def polynomial_regression(deg):\n",
    "    # transform each feature in polynomial feature\n",
    "    poly = PolynomialFeatures(degree=deg, include_bias=False)\n",
    "    poly = poly.fit(X_train_small)\n",
    "\n",
    "    # Applies the transformation\n",
    "    train_poly = poly.transform(X_train_small)\n",
    "    test_poly = poly.transform(X_test_small)\n",
    "\n",
    "    print(\"X_train_small.shape\", X_train_small.shape, \" X_poly_train.shape\", train_poly.shape)\n",
    "    print(\"X_test_small.shape\", X_test_small.shape, \" X_poly_test.shape\", test_poly.shape)\n",
    "\n",
    "    model = LinearRegression(fit_intercept=True)\n",
    "    model = model.fit(train_poly, y_train_small)\n",
    "    y_predict = model.predict(test_poly)\n",
    "    return model, y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "fc31a479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_small.shape (4492, 54)  X_poly_train.shape (4492, 54)\n",
      "X_test_small.shape (1926, 54)  X_poly_test.shape (1926, 54)\n",
      "X_train_small.shape (4492, 54)  X_poly_train.shape (4492, 1539)\n",
      "X_test_small.shape (1926, 54)  X_poly_test.shape (1926, 1539)\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "y_predict = []\n",
    "for i in range(1,3):\n",
    "    mod, pred = polynomial_regression(i)\n",
    "    models.append(mod)\n",
    "    y_predict.append(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6445575a",
   "metadata": {},
   "source": [
    "Model evaluations: forse queste metriche non hanno senso per confrontare i nostri modelli visto che hanno un numero di variabili differenti, ma sono comunque utili per capire se i nostri modelli sono buoni o no. Esempio R2 negativo indica che il nostro modello non va bene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "89b37d1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score  0.8742184860581035\n",
      "MSE score  0.0003103481929149338\n",
      "R2 score  0.7963455429548729\n",
      "MSE score  0.0005024887262227065\n"
     ]
    }
   ],
   "source": [
    "for prediction in y_predict:\n",
    "    print(\"R2 score \",r2_score(y_test_small, prediction))\n",
    "    print(\"MSE score \",mean_squared_error(y_test_small, prediction))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
