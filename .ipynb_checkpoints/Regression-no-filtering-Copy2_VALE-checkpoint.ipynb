{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f9ecf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this code to make Jupyter print every\n",
    "# printable statement and not just the last one\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# To visualize the data\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generic libraries\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Regression models\n",
    "import sklearn\n",
    "import scipy\n",
    "from scipy.stats import t\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV #split the data into training and test\n",
    "from sklearn.linear_model import LinearRegression #linear regression\n",
    "from sklearn.preprocessing import PolynomialFeatures #for polynomial regression\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# 5-folds crossvalidation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.pipeline import Pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a45d155",
   "metadata": {},
   "source": [
    "First of all, we import the dataset and we manipulate some data. We assign \"category\" type to categorical variables and we create dummy variables to treat them in a regression setting. Then, rows with NA \"ExitRates\" values are removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713b7818",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set_complete = pd.read_csv(\"data/training_set_online_shoppers_intention.csv\")\n",
    "all_categories_browser = list(range(1,14))\n",
    "all_categories_traffic_type = list(range(1,21))\n",
    "training_set_complete['Browser'] = training_set_complete['Browser'].astype('category').cat.set_categories(all_categories_browser)\n",
    "training_set_complete['TrafficType'] = training_set_complete['TrafficType'].astype('category').cat.set_categories(all_categories_traffic_type)\n",
    "training_set_complete = pd.get_dummies(training_set_complete, columns=['Month', 'OperatingSystems', 'Browser', 'Region', 'TrafficType', 'VisitorType','Weekend'], drop_first=False)\n",
    "#training_set_complete['Weekend'] = np.where(training_set_complete['Weekend']=='True',1,0)\n",
    "missing_values = training_set_complete[training_set_complete['ExitRates'].isna()]\n",
    "training_set = training_set_complete[training_set_complete['ExitRates'].isna()==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f215d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = training_set.drop(columns=['ExitRates','Revenue','Unnamed: 0'])\n",
    "y_train = training_set['ExitRates']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12592e3",
   "metadata": {},
   "source": [
    "### Variance selection\n",
    "We apply variance selection to remove all the features with a very low variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8056f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "threshold = 0.001  # Soglia di varianza desiderata\n",
    "variance_selector = VarianceThreshold(threshold=threshold)\n",
    "\n",
    "# Applicazione della selezione della varianza sul dataset\n",
    "X_train = X.loc[:, variance_selector.fit(X).get_support()]\n",
    "columns_remaining = X_train.columns.tolist()\n",
    "print(X_train.columns.tolist())\n",
    "len(columns_remaining)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332cfbf3",
   "metadata": {},
   "source": [
    "Plot of the histogram in order to have an idea of the distribution of the \"ExitRates\" variable. By looking at the plot, it seems quite asymmetrical, with peaks on the first values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1184567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotta l'istogramma\n",
    "plot = plt.hist(np.array(y), bins=30, edgecolor='black', alpha=0.7)\n",
    "\n",
    "# Aggiungi etichette e titolo al grafico\n",
    "x_lab = plt.xlabel('ExitRates distribution')\n",
    "y_lab = plt.ylabel('Frequency')\n",
    "\n",
    "# Mostra il grafico\n",
    "plt.show(plot)\n",
    "plt.show(x_lab)\n",
    "plt.show(y_lab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b132c47a",
   "metadata": {},
   "source": [
    "## 1.2 Linear and polynomial regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df11b1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_train, y_train)\n",
    "\n",
    "mse_train = mean_squared_error(y_train, lin_reg.predict(X_train))\n",
    "r2_train = r2_score(y_train, lin_reg.predict(X_train))\n",
    "\n",
    "print(\"Mean Squared Error:\", mse_train)\n",
    "print(\"R-squared:\", r2_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127924ba",
   "metadata": {},
   "source": [
    "Now we look at the coefficients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1e6953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TOGLIERE??\n",
    "\n",
    "# Create a dictionary to store feature-coefficient associations\n",
    "feature_coefficients = {}\n",
    "\n",
    "# Extract and store the coefficient for each feature\n",
    "for feature_name, coefficient in zip(X.columns, lin_reg.coef_):\n",
    "    feature_coefficients[feature_name] = coefficient\n",
    "\n",
    "# Print the feature-coefficient associations\n",
    "for feature, coefficient in feature_coefficients.items():\n",
    "    print(f\"Feature: {feature}, Coefficient: {coefficient}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea01ffa",
   "metadata": {},
   "source": [
    "Plot of the residuals for linear regression, to assess if our regression hypotheses are correct. The plot shows no particular pattern, residuals seem to be random distributed, so the assumptions are not violated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76dec22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_values = lin_reg.predict(X_train)\n",
    "residuals = y_train - predicted_values\n",
    "standardized_residuals = (residuals - np.mean(residuals)) / np.std(residuals)\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(predicted_values, standardized_residuals, color='darkblue', edgecolor='white')\n",
    "plt.axhline(y=0, color='red', linestyle='--')\n",
    "plt.xlabel('Predicted values')\n",
    "plt.ylabel('Standardized residuals')\n",
    "plt.title('Residual Plot - Linear regression')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf68099",
   "metadata": {},
   "source": [
    "Now we check if we may have a better model with polynomial features, performing a polynomial regression. The best solution, considering all the variables, is the linear one (degree = 1). We could expect this result also because the residual plot didn't show any particular pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a383a3d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "r2_scorer = make_scorer(r2_score, greater_is_better=True)\n",
    "\n",
    "# Validation\n",
    "model = Pipeline([('poly', PolynomialFeatures(degree=1, include_bias=False)),\n",
    "                  ('linear', LinearRegression(fit_intercept=True))])\n",
    "\n",
    "# Select parameters to optimize\n",
    "parameters = {'poly__degree': list(range(1,3))}\n",
    "              #'linear__fit_intercept': [True, False],\n",
    "              #'linear__normalize': [True, False]}\n",
    "\n",
    "cv = GridSearchCV(model, parameters, scoring=r2_scorer, cv=5, refit=True)\n",
    "cv.fit(X_train, y_train)\n",
    "best_polynomial_model = cv.best_estimator_\n",
    "print(\"Best Hyperparameters:\", cv.best_params_)\n",
    "print(\"Best R-squared Score:\", cv.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0721094f",
   "metadata": {},
   "source": [
    "Plot of the residuals for polynomial, to assess if our regression hypotheses are correct. The plot shows no particular pattern, residuals seem to be random distributed, so the assumptions are not violated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79431c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_values = best_polynomial_model.predict(X_train)\n",
    "residuals = y_train - predicted_values\n",
    "standardized_residuals = (residuals - np.mean(residuals)) / np.std(residuals)\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(predicted_values, standardized_residuals, color='darkblue', edgecolor='white')\n",
    "plt.axhline(y=0, color='red', linestyle='--')\n",
    "plt.xlabel('Predicted values')\n",
    "plt.ylabel('Standardized residuals')\n",
    "plt.title('Residual Plot - Polynomial regression')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb122e3a",
   "metadata": {},
   "source": [
    "## 1.3 Improvements of linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e35f16",
   "metadata": {},
   "source": [
    "We now try to improve linear regression performance by using shrinkage methods (to improve accuracy) and feature selection (to improve interpretability)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a3afdc",
   "metadata": {},
   "source": [
    "### Ridge regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6eb346",
   "metadata": {},
   "source": [
    "The $R^2$ decreased with respect to the standard linear model. It is coherent, because all our coefficients are very small and Ridge regression is more appropriate when we have some high coefficients that we want to shrink near 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8e9fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "best_degree = 1\n",
    "param_grid = {\n",
    "    'ridge__alpha': [0.01, 0.1, 1.0, 10.0]  # Add more values if needed\n",
    "}\n",
    "best_degree = 2\n",
    "pipeline = Pipeline([\n",
    "    #('poly', PolynomialFeatures(degree=best_degree, include_bias=False)),\n",
    "    ('scaler', scaler),\n",
    "    ('ridge', Ridge())  # Ridge estimator without specifying alpha\n",
    "])\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_alpha = grid_search.best_params_['ridge__alpha']\n",
    "best_estimator = grid_search.best_estimator_\n",
    "print(\"Best alpha:\", best_alpha)\n",
    "print(\"Best coefficients:\", best_estimator.named_steps['ridge'].coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e57c0cd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "best_model_ridge = grid_search.best_estimator_\n",
    "\n",
    "mse_train = mean_squared_error(y_train, best_model_ridge.predict(X_train))\n",
    "r2_train = r2_score(y_train, best_model_ridge.predict(X_train))\n",
    "\n",
    "print(\"Best alpha:\", best_alpha)\n",
    "print(\"Best coefficients:\", best_model_ridge.named_steps['ridge'].coef_)\n",
    "print(\"Mean Squared Error:\", mse_train)\n",
    "print(\"R-squared:\", r2_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a2026c",
   "metadata": {},
   "source": [
    "Plot of the residuals for linear regression with Ridge, to assess if our regression hypotheses are correct. The plot shows no particular pattern, residuals seem to be random distributed, so the assumptions are not violated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c085cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_values = best_model_ridge.predict(X_train)\n",
    "residuals = y_train - predicted_values\n",
    "standardized_residuals = (residuals - np.mean(residuals)) / np.std(residuals)\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(predicted_values, standardized_residuals, color='darkblue', edgecolor='white')\n",
    "plt.axhline(y=0, color='red', linestyle='--')\n",
    "plt.xlabel('Predicted values')\n",
    "plt.ylabel('Standardized residuals')\n",
    "plt.title('Residual Plot - Linear regression with Ridge')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a418950",
   "metadata": {},
   "source": [
    "### Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7078cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "best_degree = 1\n",
    "param_grid = {\n",
    "    'lasso__alpha': [0.01, 0.1, 1.0, 10.0]  # Add more values if needed\n",
    "}\n",
    "best_degree = 2\n",
    "pipeline = Pipeline([\n",
    "    #('poly', PolynomialFeatures(degree=best_degree, include_bias=False)),\n",
    "    ('scaler', scaler),\n",
    "    ('lasso', Lasso())  # Ridge estimator without specifying alpha\n",
    "])\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_alpha = grid_search.best_params_['lasso__alpha']\n",
    "best_estimator = grid_search.best_estimator_\n",
    "print(\"Best alpha:\", best_alpha)\n",
    "print(\"Best coefficients:\", best_estimator.named_steps['lasso'].coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f283b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_lasso = grid_search.best_estimator_\n",
    "\n",
    "mse_train = mean_squared_error(y_train, best_model_lasso.predict(X_train))\n",
    "r2_train = r2_score(y_train, best_model_lasso.predict(X_train))\n",
    "\n",
    "print(\"Best alpha:\", best_alpha)\n",
    "print(\"Best coefficients:\", best_model_lasso.named_steps['lasso'].coef_)\n",
    "print(\"Mean Squared Error:\", mse_train)\n",
    "print(\"R-squared:\", r2_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ffdc42d",
   "metadata": {},
   "source": [
    "Plot of the residuals for linear regression with Lasso, to assess if our regression hypotheses are correct. The plot shows no particular pattern, residuals seem to be random distributed, so the assumptions are not violated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c033c043",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_values = best_model_lasso.predict(X_train)\n",
    "residuals = y_train - predicted_values\n",
    "standardized_residuals = (residuals - np.mean(residuals)) / np.std(residuals)\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(predicted_values, standardized_residuals, color='darkblue', edgecolor='white')\n",
    "plt.axhline(y=0, color='red', linestyle='--')\n",
    "plt.xlabel('Predicted values - Linear regression with Lasso')\n",
    "plt.ylabel('Standardized residuals')\n",
    "plt.title('Residual Plot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784b6ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "coefficients_df = pd.DataFrame({\n",
    "    #'Feature': X.columns,\n",
    "    'Ridge Coefficients': best_model_ridge.named_steps['ridge'].coef_,\n",
    "    'Lasso Coefficients': best_model_lasso.named_steps['lasso'].coef_\n",
    "})\n",
    "\n",
    "# Print the entire DataFrame to see the coefficients with the associated variables\n",
    "coefficients_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ca14df",
   "metadata": {},
   "source": [
    "To perform an accurate evaluation of the models we compute the RMSE throug 5-cv. As we can see from the results, the linear regression shows a better score wrt ridge and lasso. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ee7cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression\n",
    "linear_reg_score = cross_val_score(lin_reg, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "linear_reg_rmse = np.sqrt(-linear_reg_score.mean())\n",
    "\n",
    "# Ridge Regression\n",
    "ridge_reg_score = cross_val_score(best_model_ridge, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "ridge_reg_rmse = np.sqrt(-ridge_reg_score.mean())\n",
    "\n",
    "# Lasso Regression\n",
    "lasso_reg_score = cross_val_score(best_model_lasso, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "lasso_reg_rmse = np.sqrt(-lasso_reg_score.mean())\n",
    "\n",
    "# Evaluation\n",
    "models = ['Linear Regression', 'Ridge Regression', 'Lasso Regression']\n",
    "rmse_scores = [linear_reg_rmse, ridge_reg_rmse, lasso_reg_rmse]\n",
    "\n",
    "for model, rmse_score in zip(models, rmse_scores):\n",
    "    print(f\"{model}: RMSE = {rmse_score}\")\n",
    "\n",
    "# Select the best model based on the RMSE score and further analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54140c02",
   "metadata": {},
   "source": [
    "## Forward stepwise selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b5e843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert back from numpy arrays to data frames\n",
    "X_all_features = list(np.delete(X.columns.values, [np.where(training_set.columns.values=='Unnamed: 0'),np.where(training_set.columns.values=='ExitRates'),np.where(training_set.columns.values=='Revenue')], axis=None))\n",
    "X_train_pd = pd.DataFrame(X_train, columns=X_all_features)\n",
    "X_test_pd = pd.DataFrame(X_test, columns=X_all_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e3681b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rss(y_true, y_pred):\n",
    "    # First we make sure the shapes are the same\n",
    "    y_true = y_true.reshape(y_pred.shape)\n",
    "    return np.sum((y_true - y_pred) ** 2)\n",
    "\n",
    "def estimate_sigma(Xtrain_pd, ytrain):\n",
    "    # Sigma is usually estimated using the model with all features\n",
    "    n, p = Xtrain_pd.shape\n",
    "    model = LinearRegression(fit_intercept=True)\n",
    "    model.fit(Xtrain_pd, ytrain)\n",
    "    y_pred = model.predict(Xtrain_pd)\n",
    "    RSS = rss(y_pred, ytrain)\n",
    "    RSE = np.sqrt(RSS / (n-p))\n",
    "    return RSE\n",
    "\n",
    "def bic(y_pred, y_true, n, d, sigma):\n",
    "    sigma2 = sigma**2\n",
    "    return (rss(y_pred, y_true) + np.log(n)*d*sigma2) / (n*sigma2)\n",
    "\n",
    "def get_sigma_scorer(metric, sigma):\n",
    "    def scorer(model, X, y):\n",
    "        n, d = X.shape\n",
    "        y_pred = model.predict(X)\n",
    "        return metric(y_pred, y, n, d, sigma)\n",
    "    \n",
    "    return scorer\n",
    "\n",
    "def get_evaluator(scorer):\n",
    "    def evaluator(model, X, y, trained=False):\n",
    "        if not trained:\n",
    "            model = model.fit(X, y)\n",
    "        score = scorer(model, X, y)\n",
    "        return model, score\n",
    "    return evaluator  \n",
    "\n",
    "from sklearn.dummy import DummyRegressor\n",
    "\n",
    "def forward_selection(Xtrain_pd, ytrain, Xtest_pd, ytest,\n",
    "                      candidates_evaluator, candidates_argbest, # Metric to be used at 2.b\n",
    "                      subsets_evaluator, subsets_argbest,       # Metric to be used at 3\n",
    "                      test_evaluator=None, test_argbest=None,\n",
    "                      verbose=True, weight_step3=0):   \n",
    "    test_evaluator = subsets_evaluator if not test_evaluator else test_evaluator\n",
    "    test_argbest = subsets_argbest if not test_argbest else test_argbest\n",
    "    \n",
    "    # Global variable init\n",
    "    # ====================\n",
    "    num_features = Xtrain_pd.shape[-1]\n",
    "    best_candidate_metric = []\n",
    "    # subsets_* are lists containing one value for each Mk model (the best of the Mk candidates)\n",
    "    subsets_test = []\n",
    "    subsets_metric = []        # The best metric of each subset of dimension 'dim'\n",
    "    subsets_best_features = [] # The best features combination in each subset of dimension 'dim'\n",
    "    # A figure to keep track of candidates scores in each Mk subset\n",
    "    num_evaluations = 0        # A conter to keep track of the total number of trials\n",
    "    \n",
    "    selected_features = []  # <------ !! We keep track of selected features !!\n",
    "    all_features = Xtrain_pd.columns\n",
    "    \n",
    "    \n",
    "    # 1. Train M0\n",
    "    # ===========\n",
    "    model = DummyRegressor()\n",
    "    # Compute (2.b) metrics\n",
    "    model, score = candidates_evaluator(model, Xtrain_pd[[]], ytrain)\n",
    "    best_candidate_metric.append(score)\n",
    "    subsets_best_features.append([])\n",
    "    # Compute metric for step 3.\n",
    "    _, score = subsets_evaluator(model, Xtrain_pd[[]], ytrain, trained=True)\n",
    "    subsets_metric.append(score)\n",
    "    _, score = test_evaluator(model, Xtrain_pd[[]], ytrain, trained=True)\n",
    "    subsets_test.append(score)\n",
    "    \n",
    "    # 2. Evaluate all Mk candidates with\n",
    "    #    k=0...P features\n",
    "    # =========================================\n",
    "    #!! The loop condition is slightly changed\n",
    "    #!! How many iterations we need to perform?\n",
    "    for dim in range(num_features):\n",
    "        candidate_metrics = [] # Keep track of candidates metrics. Will be used to select the best\n",
    "        candidate_models = []  # Keep track of candidates trained models\n",
    "        \n",
    "        # 2.a Given the previous Mk model, test remaining\n",
    "        # features and select the one providing the best\n",
    "        # performance increment\n",
    "        # ===============================================\n",
    "        remaining_features = Xtrain_pd.columns.difference(selected_features)\n",
    "        \n",
    "        for new_column in remaining_features:\n",
    "            Xtrain_sub = Xtrain_pd[selected_features+[new_column]].to_numpy()\n",
    "            model = LinearRegression(fit_intercept=True)\n",
    "            model, score = candidates_evaluator(model, Xtrain_sub, ytrain)\n",
    "            candidate_models.append(model)\n",
    "            candidate_metrics.append(score)\n",
    "            num_evaluations += 1\n",
    "            \n",
    "       \n",
    "        # 2.b Select the best candidate in (2.a)\n",
    "        # ===============================================\n",
    "        idx_best_candidate = candidates_argbest(candidate_metrics)\n",
    "        #!!! Update selected feature\n",
    "        # ==========================\n",
    "        selected_features.append(remaining_features[idx_best_candidate])\n",
    "        # Save best candidate features\n",
    "        best_candidate_metric.append(candidate_metrics[idx_best_candidate])\n",
    "        best_features = selected_features.copy()\n",
    "        subsets_best_features.append(best_features)\n",
    "        \n",
    "        # Compute metric for step 3.\n",
    "        best_subset_model = candidate_models[idx_best_candidate]\n",
    "        best_subset_Xtrain = Xtrain_pd[best_features].to_numpy()\n",
    "        _, score = subsets_evaluator(best_subset_model, best_subset_Xtrain, ytrain, trained=True)\n",
    "        subsets_metric.append(score)\n",
    "        best_subset_Xtest = Xtest_pd[best_features].to_numpy()\n",
    "        _, score_test = test_evaluator(best_subset_model, best_subset_Xtest, ytest, trained=True)\n",
    "        subsets_test.append(score_test)\n",
    "        num_evaluations += weight_step3 \n",
    "        \n",
    "        if verbose:\n",
    "            print(\"............\")\n",
    "            print(\"Best model (M{}) with {} features: {}\".format(dim, dim+1, best_features))\n",
    "            print(\"M{} subset score (3.): {}\".format(dim, score))\n",
    "        \n",
    "    # 3. Among all best candidates with increasing number\n",
    "    #    of features, select the best one\n",
    "    # ===================================================\n",
    "    best_subset_idx = subsets_argbest(subsets_metric)\n",
    "    best_features = subsets_best_features[best_subset_idx]\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"\\n\\nBest configuration has {} features\".format(best_subset_idx))\n",
    "        print(\"Features: {}\".format(subsets_best_features[best_subset_idx]))\n",
    "        print(\"Total number of trained models:\", num_evaluations)\n",
    "    return best_features\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ccb228",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = estimate_sigma(X_train_pd, y_train)\n",
    "\n",
    "best_features = forward_selection(X_train_pd, y_train, X_test_pd, y_test,\n",
    "                  get_evaluator(make_scorer(r2_score)), np.argmax, # 2.\n",
    "                  get_evaluator(get_sigma_scorer(bic, sigma)), np.argmin, # 3.\n",
    "                  get_evaluator(make_scorer(mean_squared_error)), np.argmin, # test\n",
    "                  verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db77edd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X[best_features].to_numpy()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=seed)\n",
    "\n",
    "degree = list(range(1,5))\n",
    "val_scores = np.zeros(len(degree))\n",
    "# Validation\n",
    "for i, d in enumerate(degree):\n",
    "    model = Pipeline([('poly', PolynomialFeatures(degree=d, include_bias=False)),\n",
    "                      ('linear', LinearRegression(fit_intercept=True))])\n",
    "    scores = cross_val_score(model, X_train, y_train, scoring=r2_scorer, cv=5)\n",
    "    val_scores[i] = np.mean(scores)\n",
    "\n",
    "# Identifies which is the best degree\n",
    "best_model_idx = np.argmax(val_scores)\n",
    "best_degree = degree[best_model_idx]\n",
    "# And the corresponding (best) validation score\n",
    "best_val_score = val_scores[best_model_idx]\n",
    "print(\"Best degree: \", best_degree,\n",
    "      \"\\nVal score: \", best_val_score)\n",
    "    \n",
    "    \n",
    "# Train again the Pipeline using the best parameter and the whole training set\n",
    "model = Pipeline([('poly', PolynomialFeatures(degree=best_degree, include_bias=False)),\n",
    "                  ('linear', LinearRegression(fit_intercept=True))])\n",
    "# Note: we train on X_train_small + X_val\n",
    "model = model.fit(np.concatenate([X_train]), np.concatenate([y_train]))\n",
    "y_predict = model.predict(X_test)\n",
    "test_score = r2_score(y_test, y_predict)\n",
    "\n",
    "print(\"Test score:\", test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65b0539",
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = y_test-y_predict\n",
    "plt.scatter(y_predict,residuals)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9149e5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_missing = missing_values[best_features].to_numpy()\n",
    "X_missing.shape\n",
    "values = model.predict(X_missing)\n",
    "values = np.where(values < 0, 0, values)\n",
    "values = np.where(values > 1, 1, values)\n",
    "training_set_complete.loc[:,'ExitRates'] = training_set_complete.loc[:,'ExitRates'].fillna(pd.Series(values,missing_values.index))\n",
    "training_set_complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb75228",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = pd.read_csv(\"data/test_set_online_shoppers_intention.csv\")\n",
    "test_set['Browser'] = test_set['Browser'].astype('category').cat.set_categories(all_categories_browser)\n",
    "test_set['TrafficType'] = test_set['TrafficType'].astype('category').cat.set_categories(all_categories_traffic_type)\n",
    "test_set = pd.get_dummies(test_set, columns=['Month', 'OperatingSystems', 'Browser', 'Region', 'TrafficType', 'VisitorType','Weekend'], drop_first=False)\n",
    "#test_set['Weekend'] = np.where(test_set['Weekend']=='True',1,0)\n",
    "missing_values_test = test_set[test_set['ExitRates'].isna()]\n",
    "X_missing_test = missing_values_test[best_features].to_numpy()\n",
    "X_missing_test.shape\n",
    "values_test = model.predict(X_missing_test)\n",
    "values_test = np.where(values_test < 0, 0, values_test)\n",
    "test_set.loc[:,'ExitRates'] = test_set.loc[:,'ExitRates'].fillna(pd.Series(values_test,missing_values_test.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae3ddc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set_complete.to_csv(\"training_set_complete.csv\", index=False)\n",
    "test_set.to_csv(\"test_set_complete.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b212546",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set_complete.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03941dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f4cea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(range(1,21))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5008bb42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
